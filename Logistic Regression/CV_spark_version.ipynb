{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/09 15:38:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"MySparkApp\").getOrCreate()\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def readFile(filename):\n",
    "    # Initialize Spark context\n",
    "    #spark = SparkSession.builder.appName(\"MySparkApp\").getOrCreate()\n",
    "\n",
    "    #sc = spark.sparkContext\n",
    "\n",
    "    # Read the file into an RDD\n",
    "    # Each line in the file becomes one record in the RDD\n",
    "    lines = sc.textFile(filename)\n",
    "\n",
    "    # Process each line in the RDD\n",
    "    data = lines.map(lambda line: line.split(','))\\\n",
    "                .map(lambda elem: ([float(x) for x in elem[:-1]], int(elem[-1])))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([9.012784269851089, 1672.9999766891833, 21.99998846107087, 0.9999997452701503, 61.99988768910407, 69.99980788311223, 13.000000232993186, 2.9999999785934133, 199.00000192395984, 2468369573.0148935, 2468372549.224571], 1)\n",
      "([3599.9990884099398, 48206.57583515873, 13362.999847123127, 1.0000019205086303, 262.99924185046257, 82.99988759205826, 13.999945225127506, 5.000000032871429, 216.99999612378573, 1539044199.5873349, 2468368394.7593513], 0)\n",
      "([0.0006999386757797765, 0.0009472844685660675, 53.000260213743786, 2.0000004196928174, 646242903.4069201, 82.99988759205826, 12.999999992936175, 2.999999985175615, 216.99999612378573, 2468369544.907854, 2503250078.1888514], 0)\n",
      "([3599.9990884099398, 1718.7743566535646, 63377.68872854763, 1.0000019205086303, 926682.197305462, 543.5568914038613, 12.999999992936175, 5.000000032871429, 186.99999400676145, 405749204.8178947, 1125424493.3033822], 0)\n",
      "([3471.3792185025277, 48024.1859162382, 0.00035088937602267833, 507008.9762772573, 262.99924185046257, 1000.1236755265327, 12.999999992936175, -7.710424743123667e-09, 7.999999237579246, 461400456.66477466, 98.30836248397827], 0)\n"
     ]
    }
   ],
   "source": [
    "#Testing of the read function\n",
    "filename = 'data/botnet_tot_syn_l.csv'\n",
    "RDD_Xy = readFile(filename)\n",
    "\n",
    "# Printing first 5 rows of the RDD\n",
    "for row in RDD_Xy.take(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef compute_stats(RDD):\\n    # Calculate sum and sum of squares for each feature\\n    sums = RDD.map(lambda x: x[0]).reduce(lambda a, b: [a[i] + b[i] for i in range(len(a))])\\n    return sums\\nprint(compute_stats(rdd))\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def compute_stats(RDD):\n",
    "    # Calculate sum and sum of squares for each feature\n",
    "    sums = RDD.map(lambda x: x[0]).reduce(lambda a, b: [a[i] + b[i] for i in range(len(a))])\n",
    "    return sums\n",
    "print(compute_stats(rdd))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_stds(RDD):\n",
    "    # Calculate sum and sum of squares for each feature\n",
    "    sums = RDD.map(lambda x: x[0]).reduce(lambda a, b: [a[i] + b[i] for i in range(len(a))]) \n",
    "    sum_of_squares = RDD.map(lambda x: [xi ** 2 for xi in x[0]]).reduce(lambda a, b: [a[i] + b[i] for i in range(len(a))])\n",
    "    count = RDD.count()\n",
    "\n",
    "    # Compute mean and standard deviation for each feature\n",
    "    means = [sums[i] / count for i in range(len(sums))]\n",
    "    stds = [(sum_of_squares[i] / count - (means[i]) ** 2) ** 0.5 for i in range(len(means))]\n",
    "    \n",
    "    return means, stds\n",
    "\n",
    "\n",
    "\n",
    "def normalize(RDD_Xy):\n",
    "    # Compute means and standard deviations\n",
    "    means, stds = compute_mean_stds(RDD_Xy)\n",
    "\n",
    "    # Broadcast the means and standard deviations\n",
    "    bc_means = sc.broadcast(means)\n",
    "    bc_stds = sc.broadcast(stds)\n",
    "\n",
    "    # Normalize each feature\n",
    "    def normalize_features(features, means, stds):\n",
    "        return [(features[i] - means[i]) / stds[i] if stds[i] != 0 else 0 for i in range(len(features))]\n",
    "        #return [(features[i] - means[i]) / stds[i] for i in range(len(features))]\n",
    "\n",
    "    normalized_RDD = RDD_Xy.map(lambda x: (normalize_features(x[0], bc_means.value, bc_stds.value), x[1]))\n",
    "\n",
    "    return normalized_RDD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-0.792409774778866, -0.8130937083307339, -0.4224507642218906, -0.4664697491193844, -0.5223929554497563, -0.35631956924945285, 0.7370102960327225, 0.5283496333423401, 0.8271779941619601, 0.4731661571170488, 0.15895172357621995], 1)\n",
      "([1.443720404002351, 1.1163610034798641, 0.39127563577819524, -0.4664697491031832, -0.5223920961870128, -0.35631927462193325, 0.9263319360863808, 1.480120748267978, 1.0264183320400917, -0.8286954523619166, 0.15894853159524694], 0)\n",
      "([-0.7980216574316705, -0.8824624555329105, -0.4205599209717913, -0.46646230111358483, 2.240264662197529, -0.35631927462193325, 0.7370102505822355, 0.5283496364747148, 1.0264183320400917, 0.4731661177428138, 0.185749013466657], 0)\n",
      "([1.443720404002351, -0.8111957326975887, 3.441892018491165, -0.4664697491031832, -0.5184316978805608, -0.35630883678072567, 0.7370102505822355, 1.480120748267978, 0.6943509718073647, -2.416291452741655, -0.8728693208325027], 0)\n",
      "([1.3636279869526706, 1.108798440707592, -0.42379261911074273, 3.3097260518708533, -0.5223920961870128, -0.3562984893719275, 0.7370102505822355, -0.8993069937831265, -1.2869840798639645, -2.3383314288679005, -1.7375614208186567], 0)\n"
     ]
    }
   ],
   "source": [
    "#Testing of the normalize function\n",
    "\n",
    "normalized_RDD = normalize(RDD_Xy).cache()\n",
    "\n",
    "# Print first 5 normalized rows\n",
    "for row in normalized_RDD.take(5):\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark import SparkContext\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def linear_combination(features, weights, bias):\n",
    "    return sum(weights[j] * features[j] for j in range(len(weights))) + bias\n",
    "\n",
    "def compute_gradients_and_cost(record, weights, bias):\n",
    "    xi, yi = record\n",
    "    y_hat = sigmoid(linear_combination(xi, weights, bias))\n",
    "    error = y_hat - yi\n",
    "    dw = np.zeros(len(weights))\n",
    "    for j in range(len(weights)):\n",
    "        dw[j] = error * xi[j]\n",
    "    db = error\n",
    "    cost_contribution = -yi * np.log(y_hat) - (1 - yi) * np.log(1 - y_hat)\n",
    "    return (dw, db, cost_contribution)\n",
    "\n",
    "def train(RDD_Xy, iterations, learning_rate, lambda_reg):\n",
    "    np.random.seed(0) \n",
    "    feature_count = len(RDD_Xy.first()[0])\n",
    "    w = np.random.rand(feature_count)\n",
    "    b = np.random.rand()\n",
    "    m = RDD_Xy.count()\n",
    "\n",
    "    for n in range(iterations):\n",
    "        bc_w = sc.broadcast(w)\n",
    "        bc_b = sc.broadcast(b)\n",
    "\n",
    "        gradients_and_cost = RDD_Xy.map(lambda x: compute_gradients_and_cost(x, bc_w.value, bc_b.value))\n",
    "        dw, db, total_cost = gradients_and_cost.reduce(lambda a, b: (a[0] + b[0], a[1] + b[1], a[2] + b[2]))\n",
    "\n",
    "        reg_cost = (lambda_reg / (2 * feature_count)) * np.sum(np.square(w))\n",
    "        cost = (total_cost / m) + reg_cost\n",
    "\n",
    "        w -= learning_rate * ((dw / m) + (lambda_reg/m) * w)\n",
    "        b -= learning_rate * db / m\n",
    "\n",
    "        bc_w.unpersist()\n",
    "        bc_b.unpersist()\n",
    "\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, x):\n",
    "    z = 0\n",
    "    for j in range(len(w)):\n",
    "        z += w[j] * x[j]\n",
    "\n",
    "    z+= b\n",
    "    # Compute the sigmoid of z\n",
    "    y_hat = sigmoid(z)\n",
    "\n",
    "    if y_hat > 0.5:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(w, b, RDD_Xy):\n",
    "    \n",
    "    results = RDD_Xy.map(lambda r: 1 if predict(w, b, r[0]) == r[1] else 0)\n",
    "    results = results.reduce( lambda a, b: a + b)\n",
    "\n",
    "    accuracy = results / RDD_Xy.count()\n",
    "    return accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Additional function to assign fold indices\\ndef assign_fold_index(RDD_Xy, num_folds):\\n    num_samples = RDD_Xy.count()\\n    fold_sizes = (num_samples // num_folds) * np.ones(num_folds, dtype=int)\\n    fold_sizes[:num_samples % num_folds] += 1\\n    fold_indices = np.hstack([np.full(fold_size, fold_index) for fold_index, fold_size in enumerate(fold_sizes)])\\n    np.random.shuffle(fold_indices)\\n    return RDD_Xy.zipWithIndex().map(lambda x: (fold_indices[x[1]], x[0]))\\n\\n# Cross-validation function\\ndef cross_validate(RDD_Xy, num_folds, iterations, learning_rate, lambda_reg):\\n    # Assign each row to a fold\\n    indexed_RDD = assign_fold_index(RDD_Xy, num_folds)\\n\\n    # Broadcast the indexed RDD\\n    bc_indexed_RDD = sc.broadcast(indexed_RDD.collect())\\n\\n    # Initialize array to hold accuracy for each fold\\n    fold_accuracies = []\\n\\n    # Perform cross-validation\\n    for fold in range(num_folds):\\n        train_RDD = sc.parallelize([x[1] for x in bc_indexed_RDD.value if x[0] != fold])\\n        test_RDD = sc.parallelize([x[1] for x in bc_indexed_RDD.value if x[0] == fold])\\n        \\n        # Train the model on the training set\\n        w, b = train(train_RDD, iterations, learning_rate, lambda_reg)\\n\\n        # Evaluate the model on the validation set\\n        fold_acc = accuracy(w, b, test_RDD)\\n        fold_accuracies.append(fold_acc)\\n        print(f\"Fold {fold+1}/{num_folds} - Accuracy: {fold_acc}\")\\n\\n    # Calculate average accuracy across all folds\\n    avg_acc = sum(fold_accuracies) / num_folds\\n    return avg_acc\\n\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# Additional function to assign fold indices\n",
    "def assign_fold_index(RDD_Xy, num_folds):\n",
    "    num_samples = RDD_Xy.count()\n",
    "    fold_sizes = (num_samples // num_folds) * np.ones(num_folds, dtype=int)\n",
    "    fold_sizes[:num_samples % num_folds] += 1\n",
    "    fold_indices = np.hstack([np.full(fold_size, fold_index) for fold_index, fold_size in enumerate(fold_sizes)])\n",
    "    np.random.shuffle(fold_indices)\n",
    "    return RDD_Xy.zipWithIndex().map(lambda x: (fold_indices[x[1]], x[0]))\n",
    "\n",
    "# Cross-validation function\n",
    "def cross_validate(RDD_Xy, num_folds, iterations, learning_rate, lambda_reg):\n",
    "    # Assign each row to a fold\n",
    "    indexed_RDD = assign_fold_index(RDD_Xy, num_folds)\n",
    "\n",
    "    # Broadcast the indexed RDD\n",
    "    bc_indexed_RDD = sc.broadcast(indexed_RDD.collect())\n",
    "\n",
    "    # Initialize array to hold accuracy for each fold\n",
    "    fold_accuracies = []\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for fold in range(num_folds):\n",
    "        train_RDD = sc.parallelize([x[1] for x in bc_indexed_RDD.value if x[0] != fold])\n",
    "        test_RDD = sc.parallelize([x[1] for x in bc_indexed_RDD.value if x[0] == fold])\n",
    "        \n",
    "        # Train the model on the training set\n",
    "        w, b = train(train_RDD, iterations, learning_rate, lambda_reg)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        fold_acc = accuracy(w, b, test_RDD)\n",
    "        fold_accuracies.append(fold_acc)\n",
    "        print(f\"Fold {fold+1}/{num_folds} - Accuracy: {fold_acc}\")\n",
    "\n",
    "    # Calculate average accuracy across all folds\n",
    "    avg_acc = sum(fold_accuracies) / num_folds\n",
    "    return avg_acc\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-0.792409774778866, -0.8130937083307339, -0.4224507642218906, -0.4664697491193844, -0.5223929554497563, -0.35631956924945285, 0.7370102960327225, 0.5283496333423401, 0.8271779941619601, 0.4731661571170488, 0.15895172357621995], 1, 1)\n",
      "([1.443720404002351, 1.1163610034798641, 0.39127563577819524, -0.4664697491031832, -0.5223920961870128, -0.35631927462193325, 0.9263319360863808, 1.480120748267978, 1.0264183320400917, -0.8286954523619166, 0.15894853159524694], 0, 2)\n",
      "([-0.7980216574316705, -0.8824624555329105, -0.4205599209717913, -0.46646230111358483, 2.240264662197529, -0.35631927462193325, 0.7370102505822355, 0.5283496364747148, 1.0264183320400917, 0.4731661177428138, 0.185749013466657], 0, 3)\n",
      "([1.443720404002351, -0.8111957326975887, 3.441892018491165, -0.4664697491031832, -0.5184316978805608, -0.35630883678072567, 0.7370102505822355, 1.480120748267978, 0.6943509718073647, -2.416291452741655, -0.8728693208325027], 0, 4)\n",
      "([1.3636279869526706, 1.108798440707592, -0.42379261911074273, 3.3097260518708533, -0.5223920961870128, -0.3562984893719275, 0.7370102505822355, -0.8993069937831265, -1.2869840798639645, -2.3383314288679005, -1.7375614208186567], 0, 5)\n",
      "([-0.7980216574316705, -0.8824624555329105, -0.4205599209717913, -0.46646230111358483, 2.240264662197529, -0.35631927462193325, 0.7370102505822355, 0.5283496364747148, 0.8825225954892241, 0.4731661177428138, 0.5611982951333616], 0, 6)\n",
      "([1.4436831088853912, -0.2649804454812377, -0.4237926432031121, -0.4664697491193844, -0.4037625889709445, 2.7878716329252127, -1.3456423331531824, -0.899307001329907, 0.694351051145701, 0.4731661571170488, 1.00112116725894], 1, 7)\n",
      "([1.443720404002351, 1.0908996305470706, 1.7660475715793917, -0.4664697491031832, -0.5223920961870128, -0.35631927462193325, 0.7370102505822355, 1.0042351549392934, 1.0264183320400917, -2.929478852966043, -1.7107050844558842], 0, 8)\n",
      "([-0.7980216574316705, -0.8824624555329105, 0.39127563577819524, -0.4664697491031832, 2.240264662197529, -0.35631927462193325, -1.724306491860424, 0.5283496364747148, -1.2869840798639645, 0.47316609335616366, 0.15894853159524694], 0, 9)\n",
      "([-0.730328187467246, 1.0475138825294763, 0.39127563577819524, -0.46629099709761734, -0.5223920961870128, -0.3563148927500449, -1.1563102316808158, 0.5283496364747148, 0.7275578181844657, 0.4731661177428138, 0.15894853159524694], 0, 10)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "def assign_uniform_blocks(RDD, num_blocks=10):\n",
    "\n",
    "    #here it is used a list because the integer are not global variable, so if we modify the value in the function, the\n",
    "    #change will not be seen by the next call of the function.\n",
    "    block_counter = [0]\n",
    "\n",
    "    def assign_block(record):\n",
    "        \n",
    "        block_num = (block_counter[0] % num_blocks) + 1\n",
    "        block_counter[0] += 1\n",
    "        #(block_num,) -> the ',' is used to explicit that block_num is not an integer, but a single tuple of an integer.\n",
    "        #record + (block_num,) -> is the concatenation between the tuple of record with the new one.\n",
    "        return record + (block_num,)\n",
    "\n",
    "    RDD_with_blocks = RDD.map(assign_block)\n",
    "\n",
    "    return RDD_with_blocks\n",
    "\n",
    "RDD_Xy_with_blocks = assign_uniform_blocks(normalized_RDD)\n",
    "\n",
    "for row in RDD_Xy_with_blocks.take(10):\n",
    "    print(row)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-0.792409774778866, -0.8130937083307339, -0.4224507642218906, -0.4664697491193844, -0.5223929554497563, -0.35631956924945285, 0.7370102960327225, 0.5283496333423401, 0.8271779941619601, 0.4731661571170488, 0.15895172357621995], 1, 2)\n",
      "([1.443720404002351, 1.1163610034798641, 0.39127563577819524, -0.4664697491031832, -0.5223920961870128, -0.35631927462193325, 0.9263319360863808, 1.480120748267978, 1.0264183320400917, -0.8286954523619166, 0.15894853159524694], 0, 6)\n",
      "([-0.7980216574316705, -0.8824624555329105, -0.4205599209717913, -0.46646230111358483, 2.240264662197529, -0.35631927462193325, 0.7370102505822355, 0.5283496364747148, 1.0264183320400917, 0.4731661177428138, 0.185749013466657], 0, 3)\n",
      "([1.443720404002351, -0.8111957326975887, 3.441892018491165, -0.4664697491031832, -0.5184316978805608, -0.35630883678072567, 0.7370102505822355, 1.480120748267978, 0.6943509718073647, -2.416291452741655, -0.8728693208325027], 0, 9)\n",
      "([1.3636279869526706, 1.108798440707592, -0.42379261911074273, 3.3097260518708533, -0.5223920961870128, -0.3562984893719275, 0.7370102505822355, -0.8993069937831265, -1.2869840798639645, -2.3383314288679005, -1.7375614208186567], 0, 6)\n",
      "([-0.7980216574316705, -0.8824624555329105, -0.4205599209717913, -0.46646230111358483, 2.240264662197529, -0.35631927462193325, 0.7370102505822355, 0.5283496364747148, 0.8825225954892241, 0.4731661177428138, 0.5611982951333616], 0, 6)\n",
      "([1.4436831088853912, -0.2649804454812377, -0.4237926432031121, -0.4664697491193844, -0.4037625889709445, 2.7878716329252127, -1.3456423331531824, -0.899307001329907, 0.694351051145701, 0.4731661571170488, 1.00112116725894], 1, 7)\n",
      "([1.443720404002351, 1.0908996305470706, 1.7660475715793917, -0.4664697491031832, -0.5223920961870128, -0.35631927462193325, 0.7370102505822355, 1.0042351549392934, 1.0264183320400917, -2.929478852966043, -1.7107050844558842], 0, 5)\n",
      "([-0.7980216574316705, -0.8824624555329105, 0.39127563577819524, -0.4664697491031832, 2.240264662197529, -0.35631927462193325, -1.724306491860424, 0.5283496364747148, -1.2869840798639645, 0.47316609335616366, 0.15894853159524694], 0, 6)\n",
      "([-0.730328187467246, 1.0475138825294763, 0.39127563577819524, -0.46629099709761734, -0.5223920961870128, -0.3563148927500449, -1.1563102316808158, 0.5283496364747148, 0.7275578181844657, 0.4731661177428138, 0.15894853159524694], 0, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_uniform_number(min=1, max=10):\n",
    "    # Generate a float number from uniform distribution\n",
    "    float_number = np.random.uniform(min, max + 0.9999)\n",
    "\n",
    "    # Round the float number to the nearest integer, ensuring it's between 1 and 10, inclusive\n",
    "    int_number = int(np.clip(float_number, 1, 10))\n",
    "\n",
    "    return int_number\n",
    "\n",
    "\n",
    "def assign_uniform_blocks(RDD):\n",
    "\n",
    "    def assign_block(record):\n",
    "        block_num = get_uniform_number(0, 10)\n",
    "        return record + (block_num,)\n",
    "\n",
    "    RDD_with_blocks = RDD.map(assign_block)\n",
    "\n",
    "    return RDD_with_blocks\n",
    "\n",
    "\n",
    "\n",
    "RDD_Xy_with_blocks = assign_uniform_blocks(normalized_RDD)\n",
    "\n",
    "for row in RDD_Xy_with_blocks.take(10):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for block 1 as test set: 0.9293428448380578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for block 2 as test set: 0.9275197938575723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for block 3 as test set: 0.9333451202263083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for block 4 as test set: 0.9255704395108474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for block 5 as test set: 0.9263267772772222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for block 6 as test set: 0.9319403445389258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for block 7 as test set: 0.920392465364276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for block 8 as test set: 0.9355328441457001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for block 9 as test set: 0.9267234294355502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for block 10 as test set: 0.9372205766521339\n",
      "Average Cross-Validation Accuracy: 0.9293914635846594\n"
     ]
    }
   ],
   "source": [
    "def cross_validate(RDD_Xy_with_blocks, num_blocks=10, iterations=10, learning_rate=1.5, lambda_reg=0):\n",
    "    total_accuracy = 0\n",
    "\n",
    "    for test_block in range(1, num_blocks + 1):\n",
    "        \n",
    "        training_RDD = RDD_Xy_with_blocks.flatMap(lambda x: [(x[0], x[1])] if x[-1] != test_block else [])\n",
    "        test_RDD = RDD_Xy_with_blocks.flatMap(lambda x: [(x[0], x[1])] if x[-1] == test_block else [])\n",
    "\n",
    "        w, b = train(training_RDD, iterations, learning_rate, lambda_reg)\n",
    "\n",
    "        current_accuracy = accuracy(w, b, test_RDD)\n",
    "        print(f\"Accuracy for block {test_block} as test set: {current_accuracy}\")\n",
    "\n",
    "        total_accuracy += current_accuracy\n",
    "\n",
    "    average_accuracy = total_accuracy / num_blocks\n",
    "    return average_accuracy\n",
    "\n",
    "average_accuracy = cross_validate(RDD_Xy_with_blocks)\n",
    "print(\"Average Cross-Validation Accuracy:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
